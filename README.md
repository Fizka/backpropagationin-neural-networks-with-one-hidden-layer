# backpropagationin-neural-networks-with-one-hidden-layer
Implementation of backpropagationin neural networks with one hidden layerand using three different optimization methods: SGD, minibatch SGD, and GD.

The architecture of the neural network:

– Input layer

– One hidden layer

– Output layer(one-hot encoding)

– Sigmoid activation function for the hidden layer and Softmax for the output layer.
